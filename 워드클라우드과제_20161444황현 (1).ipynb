{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import random\n",
    "import pytagcloud\n",
    "import webbrowser\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "from IPython.display import Image\n",
    "\n",
    "source_url = \"https://namu.wiki/RecentChanges\"\n",
    "\n",
    "req = requests.get(source_url)\n",
    "html = req.content\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "contents_table = soup.find(name='table')\n",
    "table_body = contents_table.find(name=\"tbody\")\n",
    "table_rows = table_body.find_all(name=\"tr\") #페이지마다 달라지는 부분\n",
    "\n",
    "page_url_base = \"https://namu.wiki\"\n",
    "page_urls = []\n",
    "for index in range(0,len(table_rows)):\n",
    "    first_td = table_rows[index].find_all('td')[0]\n",
    "    td_url = first_td.find_all('a')\n",
    "    if len(td_url) > 0:\n",
    "        page_url = page_url_base + td_url[0].get('href')\n",
    "        if 'png' not in page_url:\n",
    "            page_urls.append(page_url)\n",
    "\n",
    "page_urls = list(set(page_urls))\n",
    "\n",
    "\n",
    "columns = ['title','category','content_text']\n",
    "df = pd.DataFrame(columns = columns)\n",
    "\n",
    "for page_url in page_urls:\n",
    "    \n",
    "    req = requests.get(page_url)\n",
    "    html = req.content\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    contents_table = soup.find(name=\"article\")\n",
    "    title = contents_table.find_all('h1')[0]\n",
    "    \n",
    "    if len(contents_table.find_all('ul')) >0:\n",
    "        category =contents_table.find_all('ul')[0]\n",
    "    else :\n",
    "        category =None\n",
    "        \n",
    "    content_paragraphs = contents_table.find_all(name=\"div\", attrs={\"class\":\"wiki-paragraph\"})\n",
    "    content_corpus_list = []\n",
    "    \n",
    "    if title is not None:\n",
    "        row_title = title.text.replace('\\n', \" \")\n",
    "    else:\n",
    "        row_title = \"\"\n",
    "    \n",
    "    if content_paragraphs is not None:\n",
    "        for paragraphs in content_paragraphs:\n",
    "            if paragraphs is not None:\n",
    "                content_corpus_list.append(paragraphs.text.replace(\"\\n\", \" \"))\n",
    "            else:\n",
    "                content_corpus_list.append(\"\")\n",
    "    else:\n",
    "        content_corpus_list.append(\"\")\n",
    "        \n",
    "    if category is not None:\n",
    "        row_category = category.text.replace(\"\\n\",\" \")\n",
    "    else:\n",
    "        row_category = \"\"\n",
    "        \n",
    "    row = [row_title, row_category, \"\".join(content_corpus_list)]\n",
    "    series = pd.Series(row, index=df.columns)\n",
    "    df = df.append(series, ignore_index = True)\n",
    "\n",
    "def text_cleaning(text):\n",
    "    hangul = re.compile('[^ㄱ-ㅣ가-힣]+')\n",
    "    result =hangul.sub('',text)\n",
    "    return result\n",
    "df['title'] = df['title'].apply(lambda x : text_cleaning(x))\n",
    "df['category'] = df['category'].apply(lambda x : text_cleaning(x))\n",
    "df['content_text'] = df['content_text'].apply(lambda x : text_cleaning(x))\n",
    "\n",
    "title_corpus = \"\".join(df['title'].tolist())\n",
    "category_corpus = \"\".join(df['category'].tolist())\n",
    "content_corpus = \"\".join(df['content_text'].tolist())\n",
    "\n",
    "with open(\"korean_stopwords.txt\", encoding= 'utf8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.strip() for x in stopwords]\n",
    "\n",
    "nouns_tagger = Okt()\n",
    "nouns = nouns_tagger.nouns(title_corpus)\n",
    "count = Counter(nouns)\n",
    "\n",
    "remove_char_counter = Counter({x: count[x]for x in count if len(x)>1})\n",
    "remove_char_counter = Counter({x: remove_char_counter[x]for x in count if x not in stopwords})\n",
    "\n",
    "ranked_tags = remove_char_counter.most_common(40)\n",
    "taglist = pytagcloud.make_tags(ranked_tags, maxsize=40)\n",
    "pytagcloud.create_tag_image(taglist,'title_wordcloud.jpg', size=(400, 400), fontname='Nanum Gothic', rectangular=False)\n",
    "\n",
    "Image(filename = 'title_wordcloud.jpg')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
